{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Classification with BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RNhCZxN_ph4",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "BERT (Bidirectional Encoder Representations from Transformers) is a method of pretraining language representations.\n",
        "\n",
        "In this notebook I'm fine-tuning BERT model for sentiment classification using imdb dataset. Specifically, taking the pre-trained BERT model, adding one fully-connected layer, and training the new model for the classification task. I've compared the resulting model against a baseline Logistic Regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7dU9ENJ2P0l",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZXExgfI_qho",
        "colab_type": "code",
        "outputId": "7bcfa7b4-2a23-4c35-ea75-025f54564332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tokenizers==0.5.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykfprvsUHxSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cbefcebf-46fb-4e0f-f8bd-53c62c27e34b"
      },
      "source": [
        "!pip install pytorch-nlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.17.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB8xPwb1_2rU",
        "colab_type": "code",
        "outputId": "a7678242-ea1c-42e7-d2ea-41c58a1c1b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchnlp.datasets import imdb_dataset\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOb3z5SV_52E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = imdb_dataset(train=True, test=True)\n",
        "rn.shuffle(train_data)\n",
        "rn.shuffle(test_data)\n",
        "train_data = train_data[:1000]\n",
        "test_data = test_data[:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Oigq16t_9Lp",
        "colab_type": "code",
        "outputId": "f0bea4a8-2fd8-4ee2-8e52-a23f9cb90442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n",
        "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n",
        "\n",
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000, 100, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-quKhgoACx0",
        "colab_type": "code",
        "outputId": "2d759398-1b9c-4208-8130-87698e62e86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenizer.tokenize('Hi my name is Lidiya')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', 'my', 'name', 'is', 'lid', '##iya']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNI6arLDAKjG",
        "colab_type": "code",
        "outputId": "d56901f7-7809-4a93-b4cd-65d950fb3771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n",
        "\n",
        "len(train_tokens), len(test_tokens)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69sHG-ufAR6u",
        "colab_type": "code",
        "outputId": "2743a403-55b9-44eb-dee5-5a8f488e6d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "\n",
        "train_tokens_ids.shape, test_tokens_ids.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 512), (100, 512))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm7cAbPRAbVj",
        "colab_type": "code",
        "outputId": "abdd3836-5bb0-4594-91d8-94ca8cb476cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y = np.array(train_labels) == 'pos'\n",
        "test_y = np.array(test_labels) == 'pos'\n",
        "train_y.shape, test_y.shape, np.mean(train_y), np.mean(test_y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000,), (100,), 0.494, 0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt0Zur1SAhGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl9kLA0hAoii",
        "colab_type": "text"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbkhYIEAAnHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qZT4zT9Arz4",
        "colab_type": "code",
        "outputId": "efed9b63-2f87-4f80-d056-13a8332cea39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_VL7x8CAvg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseline_predicted = baseline_model.predict(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QblMBsO1Av7u",
        "colab_type": "code",
        "outputId": "4691b43d-d9aa-4dfa-b0b6-af1bd3b24699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(test_labels, baseline_predicted))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.80      0.88      0.84        50\n",
            "         pos       0.87      0.78      0.82        50\n",
            "\n",
            "    accuracy                           0.83       100\n",
            "   macro avg       0.83      0.83      0.83       100\n",
            "weighted avg       0.83      0.83      0.83       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PGDhNxkAyZB",
        "colab_type": "text"
      },
      "source": [
        "## BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4U2yxJMA2mp",
        "colab_type": "code",
        "outputId": "68cb5a93-6fee-40ea-ccde-ae8ebb69af4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euf-n-gDA4jv",
        "colab_type": "code",
        "outputId": "0df997a8-4a89-47ed-b548-f172da476f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.0M'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFSn_fDIF93x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc3c5b18-4076-4001-cc64-cd9b1e0d012e"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "bert_clf = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "bert_clf.cuda()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1kdqxT2B2mF",
        "colab_type": "code",
        "outputId": "f0b49ca0-fbd4-4fc2-943c-a742c2c4caa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'439.06816M'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZxfBTbqCGEA",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJiigyebB-vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFB-RupPCKhC",
        "colab_type": "code",
        "outputId": "21b2c8ed-d6b3-4b65-e28a-51f6fc45c5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).long()\n",
        "\n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).long()\n",
        "\n",
        "train_masks_tensor = torch.tensor(train_masks)\n",
        "test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'439.06816M'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTxm6zfdCMJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFWvLkICCVOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(bert_clf.parameters(), lr=3e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VOW8j68CWow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f9ce6ea-318f-460b-d30a-74c80e416b92"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "439.06816M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d22-ahgCX0x",
        "colab_type": "code",
        "outputId": "3bbf7b50-34cd-4683-855d-bd1f31fb7110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss_values = []\n",
        "for epoch_num in range(EPOCHS):\n",
        "    print('Epoch: ', epoch_num + 1)\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "        bert_clf.zero_grad()  \n",
        "        outputs = bert_clf(token_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=masks,\n",
        "                    labels=labels)\n",
        "        loss = outputs[0]\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "    avg_train_loss = train_loss / len(train_dataloader)                \n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"\")\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  10\n",
            "\n",
            "Average training loss: 0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbsXYQLSrTvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "0248986b-72ea-420c-a354-991d9eee37bc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PmCWqEsClTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction on test set\n",
        "bert_clf.eval()\n",
        "predictions, true_labels = [], []\n",
        "bert_predicted = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        outputs = bert_clf(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "        logits = outputs[0]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "        # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "        # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "        # in to a list of 0s and 1s.\n",
        "        pred_labels_i = np.argmax(logits, axis=1).flatten()\n",
        "        bert_predicted.extend(pred_labels_i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0u74W78Cqwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d2937ebb-a40e-4730-f0e9-54b4c2305170"
      },
      "source": [
        "print(classification_report(test_y, bert_predicted))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.94      0.96      0.95        50\n",
            "        True       0.96      0.94      0.95        50\n",
            "\n",
            "    accuracy                           0.95       100\n",
            "   macro avg       0.95      0.95      0.95       100\n",
            "weighted avg       0.95      0.95      0.95       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}